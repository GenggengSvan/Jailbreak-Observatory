# icml2024 - Jailbreak Research Papers

**Total Papers:** 10

## Content

- [Attack](#Attack)
  - [Text](#Attack-Text)
  - [Hybrid](#Attack-Hybrid)
- [Defense](#Defense)
  - [Text](#Defense-Text)
  - [Vision](#Defense-Vision)
- [Mechanism](#Mechanism)
  - [Text](#Mechanism-Text)

---

## Attack

### Text

| Title | First Author Affiliation | Track | Average Rating | Status | Link |
|--------|:-----:|:-----:|:-----:|:-----:|:-----:|
| Fast Adversarial Attacks on Language Models In One GPU Minute | UMD | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2024/poster/32756) |
| COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability | UIUC | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2024/poster/32666) |


### Hybrid

| Title | First Author Affiliation | Track | Average Rating | Status | Link |
|--------|:-----:|:-----:|:-----:|:-----:|:-----:|
| Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast | NUS | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2024/poster/34623) |


## Defense

### Text

| Title | First Author Affiliation | Track | Average Rating | Status | Link |
|--------|:-----:|:-----:|:-----:|:-----:|:-----:|
| RigorLLM: Resilient Guardrails for Large Language Models against Undesired Content | UIUC | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2024/poster/34098) |
| PARDEN, Can You Repeat That? Defending against Jailbreaks via Repetition | Oxford | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2024/poster/32869) |
| On Prompt-Driven Safeguarding for Large Language Models | UCLA | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2024/poster/32814) |


### Vision

| Title | First Author Affiliation | Track | Average Rating | Status | Link |
|--------|:-----:|:-----:|:-----:|:-----:|:-----:|
| Safety Fine-Tuning at (Almost) No Cost: A Baseline for Vision Large Language Models | Edinburgh | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2024/poster/33636) |


## Mechanism

### Text

| Title | First Author Affiliation | Track | Average Rating | Status | Link |
|--------|:-----:|:-----:|:-----:|:-----:|:-----:|
| A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity | UM | main | 0.0 | Oral | [ðŸ”—](https://icml.cc/virtual/2024/poster/33565) |
| Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications | Princeton | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2024/poster/34354) |
| Fundamental Limitations of Alignment in Large Language Models | HUJI | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2024/poster/34338) |



