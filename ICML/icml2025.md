# icml2025 - Jailbreak Research Papers

**Total Papers:** 23

## Content

- [Attack](#Attack)
  - [Text](#Attack-Text)
- [Defense](#Defense)
  - [Text](#Defense-Text)
- [Benchmark](#Benchmark)
  - [Text](#Benchmark-Text)
- [Mechanism](#Mechanism)
  - [Text](#Mechanism-Text)
  - [Hybrid](#Mechanism-Hybrid)
- [Other](#Other)
  - [Text](#Other-Text)
  - [Hybrid](#Other-Hybrid)

---

## Attack

### Text

| Title | First Author Affiliation | Track | Average Rating | Status | Link |
|--------|:-----:|:-----:|:-----:|:-----:|:-----:|
| Cannot See the Forest for the Trees: Invoking Heuristics and Biases to Elicit Irrational Choices of LLMs | UCAS | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2025/poster/46387) |
| Weak-to-Strong Jailbreaking on Large Language Models | UC Berkeley | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2025/poster/46335) |
| FlipAttack: Jailbreak LLMs via Flipping | NUS | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2025/poster/45738) |
| Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection | UC Berkeley | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2025/poster/45356) |
| REINFORCE Adversarial Attacks on Large Language Models: An Adaptive, Distributional, and Semantic Objective | N/A | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2025/poster/45336) |
| Adversarial Reasoning at Jailbreaking Time | UPenn | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2025/poster/44790) |
| Automated Red Teaming with GOAT: the Generative Offensive Agent Tester | Meta | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2025/poster/44754) |
| AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs | Uni TÃ¼bingen | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2025/poster/44613) |
| Speak Easy: Eliciting Harmful Jailbreaks from LLMs with Simple Interactions | Brown | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2025/poster/44478) |
| InfAlign: Inference-aware language model alignment | Google | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2025/poster/44424) |
| PANDAS: Improving Many-shot Jailbreaking via Positive Affirmation, Negative Demonstration, and Adaptive Sampling | U of T | main | 0.0 | Spotlight | [ðŸ”—](https://icml.cc/virtual/2025/poster/43847) |


## Defense

### Text

| Title | First Author Affiliation | Track | Average Rating | Status | Link |
|--------|:-----:|:-----:|:-----:|:-----:|:-----:|
| Safety Reasoning with Guidelines | THU | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2025/poster/46121) |
| Improving LLM Safety Alignment with Dual-Objective Optimization | UC Berkeley | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2025/poster/45626) |
| STAIR: Improving Safety Alignment with Introspective Reasoning | THU | main | 0.0 | Oral | [ðŸ”—](https://icml.cc/virtual/2025/poster/44809) |
| Towards LLM Unlearning Resilient to Relearning Attacks: A Sharpness-Aware Minimization Perspective and Beyond | MSU | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2025/poster/43469) |


## Benchmark

### Text

| Title | First Author Affiliation | Track | Average Rating | Status | Link |
|--------|:-----:|:-----:|:-----:|:-----:|:-----:|
| An Interpretable N-gram Perplexity Threat Model for Large Language Model Jailbreaks | Uni TÃ¼bingen | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2025/poster/44672) |
| The Jailbreak Tax: How Useful are Your Jailbreak Outputs? | ETHZ | main | 0.0 | Spotlight | [ðŸ”—](https://icml.cc/virtual/2025/poster/44418) |


## Mechanism

### Text

| Title | First Author Affiliation | Track | Average Rating | Status | Link |
|--------|:-----:|:-----:|:-----:|:-----:|:-----:|
| Blink of an eye: a simple theory for feature localization in generative models | Harvard | main | 0.0 | Oral | [ðŸ”—](https://icml.cc/virtual/2025/poster/45312) |
| Unnatural Languages Are Not Bugs but Features for LLMs | N/A | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2025/poster/44282) |
| The Hidden Dimensions of LLM Alignment: A Multi-Dimensional Analysis of Orthogonal Safety Directions | N/A | main | 0.0 | Poster | [ðŸ”—](https://icml.cc/virtual/2025/poster/43629) |


### Hybrid

| Title | First Author Affiliation | Track | Average Rating | Status | Link |
|--------|:-----:|:-----:|:-----:|:-----:|:-----:|
| How Do Large Language Monkeys Get Their Power (Laws)? | Google | main | 0.0 | Oral | [ðŸ”—](https://icml.cc/virtual/2025/poster/45319) |


## Other

### Text

| Title | First Author Affiliation | Track | Average Rating | Status | Link |
|--------|:-----:|:-----:|:-----:|:-----:|:-----:|
| Scaling Trends in Language Model Robustness | UdeM | main | 0.0 | Spotlight | [ðŸ”—](https://icml.cc/virtual/2025/poster/43784) |


### Hybrid

| Title | First Author Affiliation | Track | Average Rating | Status | Link |
|--------|:-----:|:-----:|:-----:|:-----:|:-----:|
| Position: In-House Evaluation Is Not Enough. Towards Robust Third-Party Evaluation and Flaw Disclosure for General-Purpose AI | MIT | Position | 3.8 | Spotlight | [ðŸ”—](https://icml.cc/virtual/2025/poster/40170) |


