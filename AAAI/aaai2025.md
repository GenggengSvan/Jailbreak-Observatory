# aaai2025 - Jailbreak Research Papers

**Total Papers:** 17

## Content

- [Attack](#Attack)
  - [Text](#Attack-Text)
  - [Vision](#Attack-Vision)
  - [Hybrid](#Attack-Hybrid)
- [Defense](#Defense)
  - [Text](#Defense-Text)
  - [Vision](#Defense-Vision)
- [Benchmark](#Benchmark)
  - [Vision](#Benchmark-Vision)

---

## Attack

### Text

| Title | First Author Affiliation | Track | Average Rating | Status | Link |
|--------|:-----:|:-----:|:-----:|:-----:|:-----:|
| All You Need Is S P A C E: When Jailbreaking Meets Bias Audit and Reveals What Lies Beneath the Guardrails (Student Abstract) | RIT | aaai student abstract and poster program | 0.0 | Technical | [ðŸ”—](https://ojs.aaai.org/index.php/AAAI/article/view/35249) |
| Assessing Vulnerabilities in State-of-the-Art Large Language Models Through Hex Injection (Student Abstract) | UTS | aaai student abstract and poster program | 0.0 | Technical | [ðŸ”—](https://ojs.aaai.org/index.php/AAAI/article/view/35257) |
| ChatBug: A Common Vulnerability of Aligned LLMs Induced by Chat Templates | UW | main | 0.0 | Technical | [ðŸ”—](https://ojs.aaai.org/index.php/AAAI/article/view/34945) |
| JailPO: A Novel Black-Box Jailbreak Framework via Preference Optimization Against Aligned LLMs | Fudan | main | 0.0 | Technical | [ðŸ”—](https://ojs.aaai.org/index.php/AAAI/article/view/34953) |
| LLM Stinger: Jailbreaking LLMs Using RL Fine-Tuned LLMs (Student Abstract) | Georgia Tech | aaai student abstract and poster program | 0.0 | Technical | [ðŸ”—](https://ojs.aaai.org/index.php/AAAI/article/view/35263) |
| Multi-Turn Jailbreaking Large Language Models via Attention Shifting | HUST | main | 0.0 | Technical | [ðŸ”—](https://ojs.aaai.org/index.php/AAAI/article/view/34553) |
| Perception-Guided Jailbreak Against Text-to-Image Models | NTU | main | 0.0 | Technical | [ðŸ”—](https://ojs.aaai.org/index.php/AAAI/article/view/34821) |
| Security Attacks on LLM-based Code Completion Tools | Nanjing U | main | 0.0 | Technical | [ðŸ”—](https://ojs.aaai.org/index.php/AAAI/article/view/34537) |


### Vision

| Title | First Author Affiliation | Track | Average Rating | Status | Link |
|--------|:-----:|:-----:|:-----:|:-----:|:-----:|
| FigStep: Jailbreaking Large Vision-Language Models via Typographic Visual Prompts | THU | main | 0.0 | Technical | [ðŸ”—](https://ojs.aaai.org/index.php/AAAI/article/view/34568) |
| Medical MLLM Is Vulnerable: Cross-Modality Jailbreak and Mismatched Attacks on Medical Multimodal Large Language Models | BUAA | main | 0.0 | Technical | [ðŸ”—](https://ojs.aaai.org/index.php/AAAI/article/view/32396) |


### Hybrid

| Title | First Author Affiliation | Track | Average Rating | Status | Link |
|--------|:-----:|:-----:|:-----:|:-----:|:-----:|
| Persuasion for Social Good: How to Build and Break AI | NEU | new faculty highlights | 0.0 | Technical | [ðŸ”—](https://ojs.aaai.org/index.php/AAAI/article/view/35120) |


## Defense

### Text

| Title | First Author Affiliation | Track | Average Rating | Status | Link |
|--------|:-----:|:-----:|:-----:|:-----:|:-----:|
| Look Before You Leap: Enhance Attention and Vigilance Regarding Harmful Content with GuidelineLLM | HIT | main | 0.0 | Technical | [ðŸ”—](https://ojs.aaai.org/index.php/AAAI/article/view/34784) |
| On Effects of Steering Latent Representation for Large Language Model Unlearning | JAIST | main | 0.0 | Technical | [ðŸ”—](https://ojs.aaai.org/index.php/AAAI/article/view/34544) |
| Token Highlighter: Inspecting and Mitigating Jailbreak Prompts for Large Language Models | CUHK | main | 0.0 | Technical | [ðŸ”—](https://ojs.aaai.org/index.php/AAAI/article/view/34943) |


### Vision

| Title | First Author Affiliation | Track | Average Rating | Status | Link |
|--------|:-----:|:-----:|:-----:|:-----:|:-----:|
| Internal Activation Revision: Safeguarding Vision Language Models Without Parameter Update | MBZUAI | main | 0.0 | Technical | [ðŸ”—](https://ojs.aaai.org/index.php/AAAI/article/view/34954) |


## Benchmark

### Vision

| Title | First Author Affiliation | Track | Average Rating | Status | Link |
|--------|:-----:|:-----:|:-----:|:-----:|:-----:|
| MMJ-Bench: A Comprehensive Study on Jailbreak Attacks and Defenses for Vision Language Models | ShanghaiTech | main | 0.0 | Technical | [ðŸ”—](https://ojs.aaai.org/index.php/AAAI/article/view/34983) |
| Retention Score: Quantifying Jailbreak Risks for Vision Language Models | CUHK | main | 0.0 | Technical | [ðŸ”—](https://ojs.aaai.org/index.php/AAAI/article/view/34956) |


